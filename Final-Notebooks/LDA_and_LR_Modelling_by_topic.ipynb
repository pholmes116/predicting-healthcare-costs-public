{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y3mqRk7RpXDd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as sql_f\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import to_date, datediff, floor, col, avg, substring\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import unix_timestamp\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QswLM6iYrw6Q"
      },
      "source": [
        "## 2) Creating the spark dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVf-CF8Jrw6Q"
      },
      "outputs": [],
      "source": [
        "path = '/synthea_output/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/output/csv/'\n"
      ],
      "metadata": {
        "id": "c2CyvYSwspBW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7LoWuO7AUH9a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#patient\n",
        "observations = spark.read.csv(path+\"observations.csv\", header=True)\n",
        "patient = spark.read.csv(path+\"patients.csv\", header=True)\n",
        "\n",
        "#medical\n",
        "careplans = spark.read.csv(path+\"careplans.csv\", header=True)\n",
        "conditions = spark.read.csv(path+\"conditions.csv\", header=True)\n",
        "procedures=spark.read.csv(path+\"procedures.csv\", header=True)\n",
        "encounters = spark.read.csv(path+\"encounters.csv\", header=True)\n",
        "medications = spark.read.csv(path+\"medications.csv\", header=True)\n",
        "\n",
        "#insurance and hospital\n",
        "payer_transitions=spark.read.csv(path+\"payer_transitions.csv\", header=True)\n",
        "payers=spark.read.csv(path+\"payers.csv\", header=True)\n",
        "providers=spark.read.csv(path+\"providers.csv\", header=True)\n",
        "organizations=spark.read.csv(path+\"organizations.csv\", header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XynmXh2frw6S"
      },
      "source": [
        "## 3) Cleaning dataframes and renaming variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AlZ6m6w-UVRC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# renaming columns\n",
        "patient = (\n",
        "    patient.withColumnRenamed(\"Id\", \"patient_id\")\n",
        "           .withColumnRenamed(\"MARITAL\", \"patient_marital\")\n",
        "           .withColumnRenamed(\"RACE\", \"patient_race\")\n",
        "           .withColumnRenamed(\"ETHNICITY\", \"patient_ethnicity\")\n",
        "           .withColumnRenamed(\"GENDER\", \"patient_gender\")\n",
        "           .withColumnRenamed(\"ZIP\", \"patient_zip\")\n",
        ")\n",
        "\n",
        "encounters = (\n",
        "    encounters.withColumnRenamed(\"PATIENT\", \"patient_id\")\n",
        "              .withColumnRenamed(\"Id\", \"encounter_id\")\n",
        "              .withColumnRenamed(\"DESCRIPTION\", \"encounter_description\")\n",
        "              .withColumnRenamed(\"CODE\", \"encounter_code\")\n",
        "              .withColumnRenamed(\"START\", \"encounter_start\")\n",
        "              .withColumn(\"encounter_start\", to_date(\"encounter_start\"))\n",
        "              .withColumnRenamed(\"STOP\", \"encounter_stop\")\n",
        "              .withColumn(\"encounter_stop\", to_date(\"encounter_stop\"))\n",
        "              .withColumn(\"PATIENT COST\", col(\"TOTAL_CLAIM_COST\") - col(\"PAYER_COVERAGE\"))\n",
        "              .withColumnRenamed(\"PAYER\", \"payer_id\")\n",
        "              .withColumnRenamed(\"ORGANIZATION\", \"organization_id\")\n",
        "              .withColumnRenamed(\"PROVIDER\", \"provider_id\")\n",
        ")\n",
        "\n",
        "careplans = (\n",
        "    careplans.withColumnRenamed(\"PATIENT\", \"patient_id\")\n",
        "             .withColumnRenamed(\"Id\", \"careplan_id\")\n",
        "             .withColumnRenamed(\"ENCOUNTER\", \"encounter_id\")\n",
        "             .withColumnRenamed(\"DESCRIPTION\", \"careplan_descriptions\")\n",
        "             .withColumnRenamed(\"CODE\", \"careplan_code\")\n",
        ")\n",
        "\n",
        "procedures = (\n",
        "    procedures.withColumnRenamed(\"PATIENT\", \"patient_id\")\n",
        "              .withColumnRenamed(\"ENCOUNTER\", \"encounter_id\")\n",
        "              .withColumnRenamed(\"DESCRIPTION\", \"procedure_descriptions\")\n",
        "              .withColumnRenamed(\"CODE\", \"procedure_code\")\n",
        "              .withColumnRenamed(\"DATE\", \"procedure_date\")\n",
        "              .withColumnRenamed(\"BASE_COST\", \"procedure_cost\")\n",
        ")\n",
        "\n",
        "conditions = (\n",
        "    conditions.withColumnRenamed(\"PATIENT\", \"patient_id\")\n",
        "              .withColumnRenamed(\"ENCOUNTER\", \"encounter_id\")\n",
        "              .withColumnRenamed(\"DESCRIPTION\", \"condition_description\")\n",
        "              .withColumnRenamed(\"CODE\", \"condition_code\")\n",
        "              .withColumnRenamed(\"START\", \"condition_start\")\n",
        "              .withColumnRenamed(\"END\", \"condition_end\")\n",
        ")\n",
        "\n",
        "observations = (\n",
        "    observations.withColumnRenamed(\"PATIENT\", \"patient_id\")\n",
        "                .withColumnRenamed(\"ENCOUNTER\", \"encounter_id\")\n",
        "                .withColumnRenamed(\"DATE\", \"observation_date\")\n",
        "                .withColumn(\"observation_date\", to_date(\"observation_date\"))\n",
        ")\n",
        "\n",
        "medications = (\n",
        "    medications.withColumnRenamed(\"START\", \"medication_start\")\n",
        "               .withColumn(\"medication_start\", to_date(\"medication_start\"))\n",
        "               .withColumnRenamed(\"STOP\", \"medication_stop\")\n",
        "               .withColumn(\"medication_stop\", to_date(\"medication_stop\"))\n",
        "               .withColumnRenamed(\"PATIENT\", \"patient_id\")\n",
        "               .withColumnRenamed(\"PAYER\", \"payer_id\")\n",
        "               .withColumnRenamed(\"ENCOUNTER\", \"encounter_id\")\n",
        "               .withColumnRenamed(\"CODE\", \"medication_code\")\n",
        "               .withColumnRenamed(\"DESCRIPTION\", \"medication_description\")\n",
        ")\n",
        "\n",
        "payer_transitions = (\n",
        "    payer_transitions.withColumnRenamed(\"PATIENT\", \"patient_id\")\n",
        "                     .withColumnRenamed(\"PAYER\", \"payer_id\")\n",
        ")\n",
        "\n",
        "payers = (\n",
        "    payers.withColumnRenamed(\"Id\", \"payer_id\")\n",
        "          .withColumnRenamed(\"NAME\", \"payer_name\")\n",
        "          .withColumnRenamed(\"OWNERSHIP\", \"payer_ownership\")\n",
        ")\n",
        "\n",
        "providers = (\n",
        "    providers.withColumnRenamed(\"Id\", \"provider_id\")\n",
        "             .withColumnRenamed(\"SPECIALITY\", \"provider_specialty\")\n",
        ")\n",
        "\n",
        "organizations = (\n",
        "    organizations.withColumnRenamed(\"Id\", \"organization_id\")\n",
        "                 .withColumnRenamed(\"NAME\", \"organization_name\")\n",
        "                 .withColumnRenamed(\"ZIP\", \"organization_zip\")\n",
        "                 .withColumn(\"organization_zip\", substring(col(\"organization_zip\").cast(\"string\"), 1, 5))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [],
        "id": "WM602eWOrw6T"
      },
      "outputs": [],
      "source": [
        "#can do this too\n",
        "encounters = (\n",
        "    encounters\n",
        "    .join(payers.select(\"payer_id\", \"payer_name\", \"payer_ownership\"), on=\"payer_id\", how=\"left\")\n",
        "    .join(organizations.select(\"organization_id\", \"organization_name\", \"organization_zip\"), on=\"organization_id\", how=\"left\")\n",
        "    .join(providers.select(\"provider_id\", \"provider_specialty\"), on=\"provider_id\", how=\"left\")\n",
        "    .join(procedures.select(\"encounter_id\", \"procedure_descriptions\", \"procedure_code\"), on=\"encounter_id\", how=\"left\")\n",
        "    .join(patient.select(\"patient_id\", \"BIRTHDATE\", \"patient_marital\", \"patient_race\", \"patient_ethnicity\", \"patient_gender\", \"patient_zip\"), on=\"patient_id\", how=\"left\")\n",
        "    .withColumn(\"age_at_encounter\", floor(datediff(col(\"encounter_start\"), col(\"BIRTHDATE\")) / 365.25))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2mNaI6flhLXz",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6474d3c-e79f-4226-98b4-3a40c7b1e226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+\n",
            "|encounter_description                     |\n",
            "+------------------------------------------+\n",
            "|Encounter for symptom (procedure)         |\n",
            "|Encounter for problem (procedure)         |\n",
            "|General examination of patient (procedure)|\n",
            "|General examination of patient (procedure)|\n",
            "|Encounter for problem (procedure)         |\n",
            "|General examination of patient (procedure)|\n",
            "|Consultation for treatment (procedure)    |\n",
            "|Consultation for treatment (procedure)    |\n",
            "|Patient encounter procedure (procedure)   |\n",
            "|General examination of patient (procedure)|\n",
            "|General examination of patient (procedure)|\n",
            "|General examination of patient (procedure)|\n",
            "|General examination of patient (procedure)|\n",
            "|General examination of patient (procedure)|\n",
            "|Encounter for check up (procedure)        |\n",
            "|Encounter for check up (procedure)        |\n",
            "|Encounter for check up (procedure)        |\n",
            "|Encounter for check up (procedure)        |\n",
            "|Encounter for check up (procedure)        |\n",
            "|Encounter for check up (procedure)        |\n",
            "+------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encounters.select(\"encounter_description\").show(20, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFXGaVuSrw6U",
        "outputId": "d96e98cb-a874-4acb-bb9c-4f49b4c1b56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------+\n",
            "|procedure_descriptions                                                                         |\n",
            "+-----------------------------------------------------------------------------------------------+\n",
            "|NULL                                                                                           |\n",
            "|NULL                                                                                           |\n",
            "|NULL                                                                                           |\n",
            "|NULL                                                                                           |\n",
            "|NULL                                                                                           |\n",
            "|NULL                                                                                           |\n",
            "|NULL                                                                                           |\n",
            "|NULL                                                                                           |\n",
            "|Insertion of intrauterine contraceptive device (procedure)                                     |\n",
            "|Patient referral for dental care (procedure)                                                   |\n",
            "|Assessment using Alcohol Use Disorders Identification Test - Consumption (procedure)           |\n",
            "|Assessment of substance use (procedure)                                                        |\n",
            "|Assessment of anxiety (procedure)                                                              |\n",
            "|Assessment of health and social care needs (procedure)                                         |\n",
            "|Oral health education (procedure)                                                              |\n",
            "|Examination of gingivae (procedure)                                                            |\n",
            "|Dental plain X-ray bitewing (procedure)                                                        |\n",
            "|Removal of subgingival plaque and calculus from all teeth using dental instrument (procedure)  |\n",
            "|Removal of supragingival plaque and calculus from all teeth using dental instrument (procedure)|\n",
            "|Dental care (regime/therapy)                                                                   |\n",
            "+-----------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encounters.select(\"procedure_descriptions\").show(20, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "jdIN85EFrw6U"
      },
      "source": [
        "## Trying to split by topic using LDA and train regession model per topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "arKdVR23rw6U"
      },
      "outputs": [],
      "source": [
        "modeling_df = encounters.select(\n",
        "    col(\"PATIENT COST\").cast(\"double\").alias(\"label\"),\n",
        "    col(\"age_at_encounter\").cast(\"double\"),\n",
        "    col(\"patient_marital\"),\n",
        "    col(\"patient_race\"),\n",
        "    col(\"patient_ethnicity\"),\n",
        "    col(\"patient_gender\"),\n",
        "    col(\"ENCOUNTERCLASS\"),\n",
        "    col(\"payer_ownership\"),\n",
        "    col(\"payer_name\"),\n",
        "    col(\"organization_zip\"),\n",
        "    col(\"organization_name\"),\n",
        "    col(\"procedure_code\"),\n",
        "    col(\"procedure_descriptions\"),\n",
        "    col(\"encounter_description\"),\n",
        "    col(\"encounter_code\"),\n",
        ").na.drop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [],
        "id": "ZJZJCqPZrw6V"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
        "from pyspark.ml.clustering import LDA\n",
        "from pyspark.sql.functions import col, lower, regexp_replace, concat_ws\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": [],
        "id": "bGcb-O95rw6V"
      },
      "outputs": [],
      "source": [
        "#clean the text first\n",
        "modeling_df = modeling_df.filter(\n",
        "    col(\"encounter_description\").isNotNull() &\n",
        "    col(\"procedure_descriptions\").isNotNull()\n",
        ").withColumn(\n",
        "    \"clean_encounter_text\",\n",
        "    lower(regexp_replace(col(\"encounter_description\"), \"[^a-zA-Z\\\\s]\", \"\"))\n",
        ").withColumn(\n",
        "    \"clean_procedure_text\",\n",
        "    lower(regexp_replace(col(\"procedure_descriptions\"), \"[^a-zA-Z\\\\s]\", \"\"))\n",
        ")\n",
        "\n",
        "\n",
        "modeling_df = modeling_df.withColumn(\n",
        "    \"combined_text\",\n",
        "    concat_ws(\" | \",  # Separator to distinguish sources\n",
        "        col(\"clean_encounter_text\"),\n",
        "        col(\"clean_procedure_text\")\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [],
        "id": "SOuiIOPIrw6V"
      },
      "outputs": [],
      "source": [
        "# Additional Stopwords\n",
        "stopwords=StopWordsRemover.loadDefaultStopWords(\"english\") + [\n",
        "    \"patient\", \"doctor\", \"visit\", \"care\", \"provider\", \"encounter\", \"hospital\",\"room\",\"admission\",\"procedure\"\n",
        "]\n",
        "\n",
        "# Text Preprocessing Pipeline\n",
        "tokenizer = Tokenizer(inputCol=\"combined_text\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\",stopWords=stopwords)\n",
        "vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": [],
        "id": "ex4C_cSnrw6W"
      },
      "outputs": [],
      "source": [
        "# Fit and Transform Data\n",
        "tokenized_df = tokenizer.transform(modeling_df)\n",
        "filtered_df = remover.transform(tokenized_df)\n",
        "vectorizer_model = vectorizer.fit(filtered_df)\n",
        "vectorized_df = vectorizer_model.transform(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": [],
        "id": "Fl0b09ogrw6X"
      },
      "outputs": [],
      "source": [
        "# Train LDA Model\n",
        "lda = LDA(k=11, maxIter=10, featuresCol=\"features\")\n",
        "lda_model = lda.fit(vectorized_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlM_vYParw6X",
        "outputId": "5acd740b-949a-40b8-902a-525b7c29643b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
            "|topic|termIndices             |termWeights                                                                                                      |\n",
            "+-----+------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
            "|0    |[127, 178, 282, 44, 211]|[0.0040251848984337426, 0.003963807050217229, 0.003943115615965452, 0.0038631460855705836, 0.0038372914935389467]|\n",
            "|1    |[0, 7, 12, 13, 15]      |[0.14506356257823413, 0.08443604568770224, 0.06841066273664953, 0.06825200922854656, 0.04398986820597827]        |\n",
            "|2    |[0, 1, 2, 4, 3]         |[0.17890218665107918, 0.09413377257078004, 0.08132200902760102, 0.06699595329117693, 0.0668014509224225]         |\n",
            "|3    |[0, 1, 9, 4, 22]        |[0.08097086983448099, 0.06453014492134326, 0.05891449735564754, 0.05889740978202827, 0.05857244442561762]        |\n",
            "|4    |[121, 13, 170, 276, 40] |[0.004157124283605462, 0.004115675075578371, 0.004104014737712321, 0.004063571170612919, 0.004061014786161923]   |\n",
            "|5    |[0, 25, 41, 42, 61]     |[0.060858736179238745, 0.05580558750171642, 0.04349107504954396, 0.041132952174592716, 0.023664953707869977]     |\n",
            "|6    |[0, 30, 35, 37, 45]     |[0.0506232151446903, 0.04523684588436383, 0.043648698728296874, 0.027915720855343967, 0.027785708888411417]      |\n",
            "|7    |[11, 0, 18, 19, 5]      |[0.10304155190015632, 0.09933983489616763, 0.06224742742739809, 0.06220499883507324, 0.062111259435437695]       |\n",
            "|8    |[84, 220, 189, 306, 260]|[0.00709979414921394, 0.005523530691001525, 0.005419023585960815, 0.005284532418499813, 0.005208175681726206]    |\n",
            "|9    |[136, 124, 277, 70, 170]|[0.0063082374442381284, 0.004739822287296673, 0.004354942347107446, 0.0042185881607526435, 0.004011321854024708] |\n",
            "|10   |[169, 255, 102, 152, 49]|[0.004358632342859734, 0.004110324679881321, 0.004104661474070258, 0.004096183088847761, 0.003895701558713115]   |\n",
            "+-----+------------------------+-----------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show Topics\n",
        "topics = lda_model.describeTopics(5)\n",
        "topics.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgLoJm4lrw6X",
        "outputId": "96b9b821-8648-4513-e30b-6358d0e53719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------------------------------------------+\n",
            "|topic|top_words                                            |\n",
            "+-----+-----------------------------------------------------+\n",
            "|0    |[plan, nine, episiotomy, disorders, product]         |\n",
            "|1    |[|, problem, dialysis, renal, environment]           |\n",
            "|2    |[|, check, examination, dental, general]             |\n",
            "|3    |[|, check, using, dental, plaque]                    |\n",
            "|4    |[urine, renal, intrauterine, certification, gingivae]|\n",
            "|5    |[|, , unit, intensive, administration]               |\n",
            "|6    |[|, consultation, report, test, alcohol]             |\n",
            "|7    |[health, |, social, needs, assessment]               |\n",
            "|8    |[symptom, respiratory, testing, signs, symptoms]     |\n",
            "|9    |[ward, discharge, peripheral, prone, intrauterine]   |\n",
            "|10   |[manual, bone, pregnancy, titer, treatment]          |\n",
            "+-----+-----------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vocab = vectorizer_model.vocabulary\n",
        "topics_with_words = topics.rdd.map(\n",
        "    lambda row: (row['topic'], [vocab[i] for i in row['termIndices']])\n",
        ").toDF([\"topic\", \"top_words\"])\n",
        "\n",
        "topics_with_words.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "tags": [],
        "id": "igZN-WBLrw6Y"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "import numpy as np\n",
        "\n",
        "modeling_df = lda_model.transform(vectorized_df)\n",
        "\n",
        "get_topic = udf(lambda v: int(np.argmax(v)), IntegerType())\n",
        "modeling_df = modeling_df.withColumn(\"topic\", get_topic(col(\"topicDistribution\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "tags": [],
        "id": "zAjd1xXirw6Y"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "numeric_columns = [ \"age_at_encounter\"]\n",
        "\n",
        "for column in numeric_columns:\n",
        "    modeling_df = modeling_df.withColumn(column, col(column).cast(DoubleType()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "tags": [],
        "id": "Ao_LNkwSrw6Y"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "categorical_cols = ['patient_marital', 'patient_race', 'patient_ethnicity',\n",
        "                   'patient_gender', 'ENCOUNTERCLASS',\n",
        "                   'payer_ownership',\"payer_name\",\"organization_name\", \"organization_zip\", 'procedure_code',\"encounter_code\"]\n",
        "\n",
        "for cat_col in categorical_cols:\n",
        "    indexer = StringIndexer(inputCol=cat_col, outputCol=cat_col + \"_index\", handleInvalid=\"keep\")\n",
        "    modeling_df = indexer.fit(modeling_df).transform(modeling_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "tags": [],
        "id": "TVzuuNtQrw6Z"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Define final feature list\n",
        "final_features = numeric_columns + [col + \"_index\" for col in categorical_cols] + [\"topic\"]\n",
        "\n",
        "# Drop rows with nulls in important columns\n",
        "modeling_df = modeling_df.na.drop(subset=final_features + [\"label\"])\n",
        "\n",
        "# Assemble into feature vector\n",
        "assembler = VectorAssembler(inputCols=final_features, outputCol=\"final_features\")\n",
        "modeling_df = assembler.transform(modeling_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "tags": [],
        "id": "AEuqH6XMrw6Z"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "models = {}\n",
        "topics = modeling_df.select(\"topic\").distinct().rdd.flatMap(lambda x: x).collect()\n",
        "\n",
        "for t in topics:\n",
        "    topic_df = modeling_df.filter(col(\"topic\") == t)\n",
        "    lr = LinearRegression(featuresCol=\"final_features\", labelCol=\"label\",regParam=0.1) #might not need regParam with a bigger dataset\n",
        "    model = lr.fit(topic_df)\n",
        "    models[t] = model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPPwTIpdrw6Z",
        "outputId": "adc7ec7e-d93a-454b-ffbd-ac92efe5fe98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------------+-----+\n",
            "|label             |prediction        |topic|\n",
            "+------------------+------------------+-----+\n",
            "|142.0             |2528.5285189819697|1    |\n",
            "|142.0             |2824.8259316420126|1    |\n",
            "|142.0             |2330.9969105419414|1    |\n",
            "|142.0             |2182.8482042119203|1    |\n",
            "|142.0             |2182.8482042119203|1    |\n",
            "|143.20000000000005|2380.3798126519487|1    |\n",
            "|1250.85           |1385.6669808209908|1    |\n",
            "|9694.170000000002 |2386.491407506738 |1    |\n",
            "|9694.170000000002 |2534.64011383676  |1    |\n",
            "|0.0               |3706.443357840976 |1    |\n",
            "+------------------+------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from functools import reduce\n",
        "from pyspark.sql import DataFrame\n",
        "\n",
        "def unionAll(*dfs):\n",
        "    return reduce(DataFrame.unionByName, dfs)\n",
        "\n",
        "predictions_list = []\n",
        "\n",
        "for t, model in models.items():\n",
        "    topic_df = modeling_df.filter(col(\"topic\") == t)\n",
        "    preds = model.transform(topic_df)\n",
        "    predictions_list.append(preds)\n",
        "\n",
        "final_predictions = unionAll(*predictions_list)\n",
        "final_predictions.select(\"label\", \"prediction\", \"topic\").show(10, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxmWsB7mrw6Z",
        "outputId": "a7365030-1749-4304-8760-359c65a5ab4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE for topic 1: 1878.223558554715\n",
            "RMSE for topic 6: 285.8947994782201\n",
            "RMSE for topic 3: 2284.193572808087\n",
            "RMSE for topic 5: 2558.592566886567\n",
            "RMSE for topic 9: 0.02059086411394987\n",
            "RMSE for topic 4: 0.09092650811243945\n",
            "RMSE for topic 8: 93.81029666191061\n",
            "RMSE for topic 7: 719.7302145007224\n",
            "RMSE for topic 2: 899.7499943821864\n",
            "RMSE for topic 0: 0.0\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "rmse_per_topic = {}\n",
        "for t in topics:\n",
        "    topic_predictions = final_predictions.filter(col(\"topic\") == t)\n",
        "    rmse = evaluator.evaluate(topic_predictions)\n",
        "    rmse_per_topic[t] = rmse\n",
        "\n",
        "for topic, rmse in rmse_per_topic.items():\n",
        "    print(f\"RMSE for topic {topic}: {rmse}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "PySpark",
      "language": "python",
      "name": "pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}